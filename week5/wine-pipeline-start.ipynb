{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"0\">Wine Data Exercises</a>\n",
    "\n",
    "In this notebook, we will review basic steps of exploratory data analysis following the example in the EDA-PIPELINE.ipynb example. We will work with the wine data set __winequality-white.csv__ provided in the __data__ folder. \n",
    "\n",
    "__Dataset schema:__ \n",
    "   - fixed acidity\n",
    "   - volatile acidity\n",
    "   - citric acid\n",
    "   - residual sugar\n",
    "   - chlorides\n",
    "   - free sulfur dioxide\n",
    "   - total sulfur dioxide\n",
    "   - density\n",
    "   - pH\n",
    "   - sulphates\n",
    "   - alcohol\n",
    "\n",
    "   Output variable (based on sensory data): \n",
    "   - quality (score between 0 and 10)\n",
    "\n",
    "\n",
    "You will follow the same steps in the _EDA-PIPELINE.ipynb_ notebook to complete the wine quality classification tasks. The section headers are provided,  and you will need to copy and paste the code over, while adding necessary modifications. \n",
    "\n",
    "1. <a href=\"#1\">Overall Statistics</a>\n",
    "2. <a href=\"#2\">Select Feature Columns</a>\n",
    "3. <a href=\"#3\">Basic Plots</a>\n",
    "4. <a href=\"#4\">Impute Missing Values</a>\n",
    "5. <a href=\"#5\">Preparing Training and Test Datasets</a>\n",
    "6. <a href=\"#6\">Data Processing with Pipeline</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id=\"=1\">Overall Statistics</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To do: read the dataset into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id=\"2\">Select Feature Columns</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To do: separate model features and model target."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id=\"3\">Basic Plots</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "### Bar Plots and Histograms\n",
    "\n",
    "\n",
    "\n",
    "__Bar plots__: These plots show counts of categorical data fields. __value_counts()__ function yields the counts of each unique value. It is useful for categorical variables.\n",
    "\n",
    "To do: let's look at the distribution of the model target by numbers; Then plot the distribution using a bar plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Histograms:__ Histograms show distribution of numeric data. Data is divided into intervals, aka, \"buckets\" or \"bins\".\n",
    "\n",
    "To do: plot the histograms for at least two numeric features. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot and Correlation Matrix\n",
    "\n",
    "To do: Plot the scatter plot for two selected numeric features.\n",
    "\n",
    "To do: Plot the correlation matrix. Correlation scores are calculated for numerical fields. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id=\"4\">Impute Missing Values</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n",
    "__Imputing Numerical Values:__ The easiest way to impute numerical values is to get the __average (mean) value__ for the corresponding column and use that as the new value for each missing record in that column. \n",
    "\n",
    "To do: implement imputation is using sklearn's __SimpleImputer__, a class implementing .fit() and .transform() methods. Save the processed data in a new data frame named df_sklearn_imputed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id=\"5\">Preparing Training and Test Datasets</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To do: split our dataset into training (90%) and test (10%) subsets using sklearn's [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a id=\"6\">Data Processing with Pipeline</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "\n",
    "To do: build a pipeline to impute the missing values with the mean using sklearn's SimpleImputer, scale the numerical features to have similar orders of magnitude by bringing them into the 0-1 range with sklearn's MinMaxScaler, and finally train a KNN estimator on the imputed and scaled dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: Evaluate the pipeline with the test data. Produce the confusion matrix and the classification reports using \n",
    "[__confusion_matrix()__](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) and \n",
    "\n",
    "\n",
    "[__classification_report()__](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eba38789ab565d76f074e8fa97ecc7da63eb4a5e1ba28cc348f16f5285783ca7"
  },
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
